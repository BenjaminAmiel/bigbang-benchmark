import streamlit as st
import json
import os
import openai
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# --- ğŸ”§ Fonction de normalisation ---
def normalize(text):
    text = text.lower()
    replacements = {
        "zero": "0", "one": "1", "two": "2", "three": "3",
        "four": "4", "five": "5", "six": "6", "seven": "7",
        "eight": "8", "nine": "9"
    }
    for word, digit in replacements.items():
        text = text.replace(word, digit)
    for digit, word in replacements.items():
        text = text.replace(digit, word)
    return ''.join(e for e in text if e.isalnum())

# --- ğŸš€ Interface Streamlit ---
st.set_page_config(page_title="Big Bang Benchmark", layout="wide")
st.title("ğŸš€ Big Bang Benchmark")

# --- ğŸ”‘ ClÃ© API ---
api_key = st.text_input("ğŸ”‘ OpenAI API Key", type="password")

# --- ğŸ¤– SÃ©lection du modÃ¨le ---
model_choice = st.selectbox("ğŸ¤– Choisir le modÃ¨le OpenAI", ["gpt-3.5-turbo", "gpt-4", "gpt-4o"])

# --- âœ… Si clÃ© API entrÃ©e ---
if api_key:
    st.success("ClÃ© chargÃ©e avec succÃ¨s âœ…")
    openai.api_key = api_key

    # --- ğŸ“‚ Charger le dataset ---
    with open("dataset.json") as f:
        dataset = json.load(f)

    # --- âš™ï¸ Fonction appel modÃ¨le ---
    def gpt_model(prompt):
        response = openai.ChatCompletion.create(
            model=model_choice,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()

    # --- ğŸ“Š Evaluation ---
    results = []
    for item in dataset:
        q, expected = item['question'], item['answer']
        with st.spinner(f"â³ Ã‰valuation : {q}"):
            response = gpt_model(q)
            norm_expected = normalize(expected)
            norm_response = normalize(response)
            exact = norm_expected == norm_response

            # SimilaritÃ© cosinus
            vectorizer = TfidfVectorizer().fit_transform([norm_expected, norm_response])
            sim_score = cosine_similarity(vectorizer)[0, 1]

            results.append({
                "question": q,
                "expected": expected,
                "response": response,
                "correct": exact,
                "similarity": round(sim_score, 4)
            })

    st.success("Benchmark terminÃ© âœ…")

    # --- ğŸ“„ Affichage ---
    st.subheader("RÃ©sultats")
    for idx, r in enumerate(results):
        st.markdown(f"### ğŸ§  Question {idx + 1}")
        st.markdown(f"**â“ Question** : {r['question']}")
        st.markdown(f"**âœ… Attendu** : {r['expected']}")
        st.markdown(f"**ğŸ’¬ RÃ©ponse** : {r['response']}")
        if r['correct']:
            st.success("ğŸ¯ Correct")
        else:
            st.error("âŒ Incorrect")
            st.markdown(f"ğŸ” Similarity score: `{r['similarity']}`")

    # --- ğŸ’¾ Exporter les rÃ©sultats ---
    with open("evaluation_results.json", "w") as f:
        json.dump(results, f, indent=2)
