# ğŸš€ Big Bang Benchmark

**Big Bang Benchmark** est un outil dâ€™Ã©valuation minimaliste, Ã©lÃ©gant et puissant, conÃ§u pour tester les performances des modÃ¨les dâ€™IA sur des questions fondamentales.  
Il rÃ©vÃ¨le la capacitÃ© dâ€™un modÃ¨le Ã  produire des rÃ©ponses claires, correctes et alignÃ©es avec des attentes humaines simples et prÃ©cises.

---

## âœ¨ Objectif

Permettre Ã  la communautÃ© mondiale de comparer facilement la qualitÃ© de diffÃ©rents modÃ¨les dâ€™IA Ã  travers une grille de lecture universelle,  
basÃ©e sur la justesse, la cohÃ©rence et la sÃ©mantique.

---

## ğŸ§  Fonctionnement

- `evaluate_model.py` : exÃ©cute une sÃ©rie de questions sur un modÃ¨le et gÃ©nÃ¨re un fichier `evaluation_results.json` avec les rÃ©sultats.
- `app.py` : interface **Streamlit** pour visualiser les rÃ©ponses, leur exactitude et leur pertinence sÃ©mantique.

---

## âœ… Usage local

1. Cloner le dÃ©pÃ´t :

```bash
git clone https://github.com/BenjaminAmiel/bigbang-benchmark.git
cd bigbang-benchmark
